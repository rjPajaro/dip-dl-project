{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this happened\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"this happened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "folder = 'pure_amd_pickled'\n",
    "\n",
    "pickle_in = open(folder + '/' + 'ODIR_AMD_w_others_pred.pickle','rb')\n",
    "ODIR_AMD_w_others = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(folder + '/' + 'ODIR_Pure_AMD_pred.pickle','rb')\n",
    "ODIR_Pure_AMD = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(folder + '/' + 'RFMID_AMD_w_others_pred.pickle','rb')\n",
    "RFMID_AMD_w_others = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(folder + '/' + 'RFMID_Pure_AMD_pred.pickle','rb')\n",
    "RFMID_Pure_AMD = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(folder + '/' + 'RFMID_normal_pred.pickle','rb')\n",
    "RFMID_normal = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(folder + '/' + 'stare_AMD_w_others_pred.pickle','rb')\n",
    "stare_AMD_w_others = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(folder + '/' + 'stare_normal_pred.pickle','rb')\n",
    "stare_normal = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "258\n",
      "132\n",
      "36\n",
      "72\n",
      "480\n",
      "80\n",
      "amd =  574\n"
     ]
    }
   ],
   "source": [
    "print(len(ODIR_AMD_w_others))\n",
    "print(len(ODIR_Pure_AMD))\n",
    "print(len(RFMID_AMD_w_others))\n",
    "print(len(RFMID_Pure_AMD))\n",
    "print(len(stare_AMD_w_others))\n",
    "print(len(RFMID_normal[:480]))\n",
    "print(len(stare_normal))\n",
    "\n",
    "print('amd = ', len(stare_AMD_w_others) + len(RFMID_Pure_AMD) + len(RFMID_AMD_w_others) + len(ODIR_Pure_AMD) + len(ODIR_AMD_w_others))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_amd_mixed = np.concatenate((ODIR_AMD_w_others, ODIR_Pure_AMD, RFMID_AMD_w_others, RFMID_Pure_AMD, stare_AMD_w_others), axis=0)\n",
    "segmented_pure_amd = np.concatenate((ODIR_Pure_AMD, RFMID_Pure_AMD), axis=0)\n",
    "segmented_normal = np.concatenate((RFMID_normal[:480], stare_normal), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_amd = []\n",
    "y_normal = []\n",
    "\n",
    "for i in range(len(segmented_amd_mixed)):\n",
    "    y_amd.append(1)\n",
    "\n",
    "for i in range(len(segmented_normal)):\n",
    "    y_normal.append(0)\n",
    "\n",
    "label_amd = np.array(y_amd)\n",
    "label_normal = np.array(y_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((segmented_amd_mixed, segmented_normal), axis=0)\n",
    "y = np.concatenate((label_amd, label_normal), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array(x/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, alpha, y_train, omega = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_eval, x_test, y_eval, y_test = train_test_split(alpha, omega, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 510, 510, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 255, 255, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 253, 253, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 126, 126, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1016064)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               130056320 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,075,265\n",
      "Trainable params: 130,075,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(512, 512, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size and number of epochs for training\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "model_filename = 'method_v1.h5'\n",
    "callback_checkpoint =[EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=False),\n",
    "ModelCheckpoint(\n",
    "    model_filename, \n",
    "    verbose=1, \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True,\n",
    "),\n",
    "ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15, min_lr=1e-7, verbose=1),\n",
    "TensorBoard()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(907, 512, 512, 1)\n",
      "(907,)\n",
      "(113, 512, 512, 1)\n",
      "(113,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_eval.shape)\n",
    "print(y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.7409\n",
      "Epoch 1: val_loss improved from inf to 0.52884, saving model to method_v1.h5\n",
      "227/227 [==============================] - 27s 98ms/step - loss: 0.5475 - accuracy: 0.7409 - val_loss: 0.5288 - val_accuracy: 0.8142 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.4821 - accuracy: 0.7982\n",
      "Epoch 2: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.4821 - accuracy: 0.7982 - val_loss: 0.6535 - val_accuracy: 0.7965 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.8490\n",
      "Epoch 3: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.4048 - accuracy: 0.8490 - val_loss: 0.5663 - val_accuracy: 0.8053 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.2885 - accuracy: 0.8875\n",
      "Epoch 4: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 12s 53ms/step - loss: 0.2885 - accuracy: 0.8875 - val_loss: 1.8086 - val_accuracy: 0.8142 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.8964\n",
      "Epoch 5: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 12s 51ms/step - loss: 0.2701 - accuracy: 0.8964 - val_loss: 0.9121 - val_accuracy: 0.7699 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.3019 - accuracy: 0.9027\n",
      "Epoch 6: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.3009 - accuracy: 0.9030 - val_loss: 0.8437 - val_accuracy: 0.8053 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9272\n",
      "Epoch 7: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.2182 - accuracy: 0.9272 - val_loss: 1.4622 - val_accuracy: 0.8053 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1885 - accuracy: 0.9325\n",
      "Epoch 8: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1882 - accuracy: 0.9327 - val_loss: 1.6917 - val_accuracy: 0.7699 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 0.9336\n",
      "Epoch 9: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1714 - accuracy: 0.9338 - val_loss: 2.0853 - val_accuracy: 0.7876 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9369\n",
      "Epoch 10: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1638 - accuracy: 0.9372 - val_loss: 2.1663 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.9369\n",
      "Epoch 11: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1595 - accuracy: 0.9372 - val_loss: 2.6404 - val_accuracy: 0.7699 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9350\n",
      "Epoch 12: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1647 - accuracy: 0.9350 - val_loss: 2.8115 - val_accuracy: 0.7876 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.9372\n",
      "Epoch 13: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1564 - accuracy: 0.9372 - val_loss: 2.6410 - val_accuracy: 0.7965 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1735 - accuracy: 0.9358\n",
      "Epoch 14: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1730 - accuracy: 0.9361 - val_loss: 2.6247 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1751 - accuracy: 0.9314\n",
      "Epoch 15: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1749 - accuracy: 0.9316 - val_loss: 2.8490 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1839 - accuracy: 0.9303\n",
      "Epoch 16: val_loss did not improve from 0.52884\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1833 - accuracy: 0.9305 - val_loss: 1.9792 - val_accuracy: 0.8142 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1532 - accuracy: 0.9369\n",
      "Epoch 17: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1530 - accuracy: 0.9372 - val_loss: 2.0297 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.9369\n",
      "Epoch 18: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1523 - accuracy: 0.9372 - val_loss: 2.0587 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1522 - accuracy: 0.9369\n",
      "Epoch 19: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 49ms/step - loss: 0.1517 - accuracy: 0.9372 - val_loss: 2.0513 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1509 - accuracy: 0.9381\n",
      "Epoch 20: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1513 - accuracy: 0.9383 - val_loss: 2.0938 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.9381\n",
      "Epoch 21: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 12s 51ms/step - loss: 0.1512 - accuracy: 0.9383 - val_loss: 2.1284 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1510 - accuracy: 0.9381\n",
      "Epoch 22: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1506 - accuracy: 0.9383 - val_loss: 2.1410 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9383\n",
      "Epoch 23: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 12s 51ms/step - loss: 0.1509 - accuracy: 0.9383 - val_loss: 2.2103 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1507 - accuracy: 0.9381\n",
      "Epoch 24: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1505 - accuracy: 0.9383 - val_loss: 2.2482 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1503 - accuracy: 0.9381\n",
      "Epoch 25: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1501 - accuracy: 0.9383 - val_loss: 2.2914 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.9383\n",
      "Epoch 26: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1499 - accuracy: 0.9383 - val_loss: 2.2757 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9383\n",
      "Epoch 27: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1501 - accuracy: 0.9383 - val_loss: 2.3270 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9383\n",
      "Epoch 28: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1495 - accuracy: 0.9383 - val_loss: 2.2967 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9381\n",
      "Epoch 29: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1497 - accuracy: 0.9383 - val_loss: 2.3427 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9383\n",
      "Epoch 30: val_loss did not improve from 0.52884\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1493 - accuracy: 0.9383 - val_loss: 2.3912 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1498 - accuracy: 0.9381\n",
      "Epoch 31: val_loss did not improve from 0.52884\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "227/227 [==============================] - 11s 50ms/step - loss: 0.1494 - accuracy: 0.9383 - val_loss: 2.4466 - val_accuracy: 0.8053 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"GPU\"):\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_eval, y_eval),\n",
    "        callbacks=[callback_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 15ms/step - loss: 0.8240 - accuracy: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.823965847492218, 0.8684210777282715]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 235ms/step\n",
      "Predictions:  114\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(model_filename)\n",
    "with tf.device(\"GPU\"): \n",
    "    result = model.predict(x_test)\n",
    "\n",
    "print('Predictions: ', len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m data \u001b[39m=\u001b[39m { \u001b[39m'\u001b[39m\u001b[39mActual\u001b[39m\u001b[39m'\u001b[39m: y_test, \u001b[39m'\u001b[39m\u001b[39mPredicted\u001b[39m\u001b[39m'\u001b[39m: result }\n\u001b[1;32m----> 4\u001b[0m preds \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data)\n\u001b[0;32m      6\u001b[0m preds\n",
      "File \u001b[1;32mc:\\Users\\Randall\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Randall\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Randall\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Randall\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:653\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    651\u001b[0m         raw_lengths\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(val))\n\u001b[0;32m    652\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(val, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m val\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 653\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    655\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m indexes \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m    656\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf using all scalar values, you must pass an index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = { 'Actual': y_test, 'Predicted': result }\n",
    "preds = pd.DataFrame(data)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2109169e-01],\n",
       "       [5.6711721e-01],\n",
       "       [3.0537513e-01],\n",
       "       [2.2109175e-01],\n",
       "       [2.2109175e-01],\n",
       "       [5.1980180e-01],\n",
       "       [6.6258299e-01],\n",
       "       [7.1378791e-01],\n",
       "       [3.8081431e-01],\n",
       "       [7.5118470e-01],\n",
       "       [2.2109169e-01],\n",
       "       [7.8549874e-01],\n",
       "       [7.2677970e-01],\n",
       "       [2.2109175e-01],\n",
       "       [9.0685475e-04],\n",
       "       [4.9718860e-01],\n",
       "       [2.9597819e-01],\n",
       "       [2.2109175e-01],\n",
       "       [2.2109175e-01],\n",
       "       [2.2109175e-01],\n",
       "       [3.9299610e-01],\n",
       "       [4.7605953e-01],\n",
       "       [2.2109175e-01],\n",
       "       [2.2109175e-01],\n",
       "       [9.8928553e-01],\n",
       "       [5.8181775e-01],\n",
       "       [4.8580456e-01],\n",
       "       [9.7520918e-01],\n",
       "       [9.9845421e-01],\n",
       "       [4.3961406e-01],\n",
       "       [9.8902273e-01],\n",
       "       [9.9994576e-01],\n",
       "       [6.8029606e-01],\n",
       "       [5.2041441e-01],\n",
       "       [9.9885821e-01],\n",
       "       [2.2109175e-01],\n",
       "       [2.2109175e-01],\n",
       "       [6.1062068e-01],\n",
       "       [2.2109175e-01],\n",
       "       [7.0001203e-01],\n",
       "       [2.2109175e-01],\n",
       "       [9.0680236e-04],\n",
       "       [2.2109175e-01],\n",
       "       [9.9385804e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9184495e-01],\n",
       "       [5.5421227e-01],\n",
       "       [3.2507855e-01],\n",
       "       [7.1208078e-01],\n",
       "       [2.2109175e-01],\n",
       "       [4.2786020e-01],\n",
       "       [6.7025965e-01],\n",
       "       [9.9349701e-01],\n",
       "       [4.6426237e-01],\n",
       "       [3.1235087e-01],\n",
       "       [2.2109175e-01],\n",
       "       [3.9991412e-01],\n",
       "       [8.4897316e-01],\n",
       "       [2.2109175e-01],\n",
       "       [9.9997365e-01],\n",
       "       [9.9184579e-01],\n",
       "       [2.2109175e-01],\n",
       "       [4.3100026e-01],\n",
       "       [9.9184495e-01],\n",
       "       [2.2109169e-01],\n",
       "       [6.2515241e-01],\n",
       "       [2.2109175e-01],\n",
       "       [9.9687612e-01],\n",
       "       [2.2109175e-01],\n",
       "       [9.7324455e-01],\n",
       "       [2.2109169e-01],\n",
       "       [9.2320126e-01],\n",
       "       [6.2281978e-01],\n",
       "       [2.2109175e-01],\n",
       "       [9.9993753e-01],\n",
       "       [2.2109175e-01],\n",
       "       [2.2109175e-01],\n",
       "       [4.4224316e-01],\n",
       "       [4.2855826e-01],\n",
       "       [4.3572471e-01],\n",
       "       [6.7766875e-01],\n",
       "       [4.3332836e-01],\n",
       "       [4.2626452e-01],\n",
       "       [5.6711638e-01],\n",
       "       [2.2109175e-01],\n",
       "       [4.6767449e-01],\n",
       "       [2.2109175e-01],\n",
       "       [2.2109175e-01],\n",
       "       [9.9980634e-01],\n",
       "       [2.2109175e-01],\n",
       "       [2.2109175e-01],\n",
       "       [2.2109175e-01],\n",
       "       [9.9762720e-01],\n",
       "       [2.2109175e-01],\n",
       "       [4.2791930e-01],\n",
       "       [2.2109175e-01],\n",
       "       [7.0463490e-01],\n",
       "       [9.9836832e-01],\n",
       "       [9.0681022e-04],\n",
       "       [4.7574264e-01],\n",
       "       [3.7030938e-01],\n",
       "       [7.7873009e-01],\n",
       "       [4.8782277e-01],\n",
       "       [9.9808514e-01],\n",
       "       [4.3115139e-01],\n",
       "       [9.7537929e-01],\n",
       "       [4.4338846e-01],\n",
       "       [2.2109184e-01],\n",
       "       [5.2201629e-01],\n",
       "       [9.8704648e-01],\n",
       "       [9.9987066e-01],\n",
       "       [2.2109184e-01],\n",
       "       [6.4681017e-01],\n",
       "       [9.7201455e-01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
